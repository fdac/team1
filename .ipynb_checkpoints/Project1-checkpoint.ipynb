{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Project 1: Discover BitBucket code repositories\n",
      "\n",
      "## Context\n",
      "You work for a cloud application provider DeveloperParadise that needs to convince its investors \n",
      "that their business has a bright future.\n",
      "\n",
      "Your task is to show that the number of customers (users of DeveloperParadise, which happens to \n",
      "compete with Atlassian's BitBucket) is comparable to that of  BitBucket. The presentation for investors \n",
      "is next week (completely incidentally, exactly on the day this project is due). \n",
      "\n",
      "Feel free to use examples below or any other information you can gather to obtain as complete as possible list of \n",
      "users and repositories hosted on BitBucket.\n",
      "\n",
      "While a template for the search strategy is provided, feel free to use any means (including borrowing with attribution from the other teams) to get as many as you can within this very short but, unfortunately, very realistic time frame.  \n",
      "\n",
      "\n",
      "## Important Notes\n",
      "\n",
      "Please keep in mind operational data pitfalls, such as \n",
      "   * lack of context \n",
      "   * missing data\n",
      "   * possibly incorrect data\n",
      "\n",
      "1. DeveloperParadise may focus on specific types of customers (e.g., size, programming language, or other characteristics), and that number is a subset of all customers. \n",
      " * Pick the desired characteristics of target customers for DeveloperParadise and estimate their percentage is in your retrieved set\n",
      "1. Is there any way to estimate what fraction of all BitBucket customers/repositories are in the retrieved set?\n",
      "1. Is the distribution of different types of customers the same in the retrieved and undiscovered sets of BitBucket customers? "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Example 1. Search for a keyword 'test'\n",
      "\n",
      "* Unfortunately, BitBucket does not have a documented search API\n",
      "\n",
      "So feel free to experiment with an undocumented search API below that appears to \n",
      "yeld some results, though it is not clear how complete they are and \n",
      "how exactly the results are provided by BitBucket.  You don't need to \n",
      "follow the search strategy outlined below, it is just one of many possible approaches.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import requests, json, sys, time, re, BeautifulSoup\n",
      "key = 'test'\n",
      "URL = 'https://bitbucket.org/repo/all?name=' + key\n",
      "r = requests .get(URL)\n",
      "t = r.text\n",
      "soup = BeautifulSoup.BeautifulSoup(t)\n",
      "start = 0\n",
      "npages = 1\n",
      "for link in soup.findAll('a'):\n",
      "    if (start == 3): continue\n",
      "    s = link.get('href')\n",
      "    if (start == 0):\n",
      "        if ('/account/signin/?next' in s):\n",
      "            start = 1\n",
      "            continue\n",
      "        else:\n",
      "            continue   \n",
      "    if  s == '#': continue \n",
      "        \n",
      "    # This is the way the remaining pages in the search results are marked\n",
      "    m = re.search(r'^/repo/all/(\\d*)\\?', s)\n",
      "    if  m:\n",
      "        start = 2\n",
      "        #get max num\n",
      "        i = m.group(1)\n",
      "        if (int(i) > npages): npages = int(i)\n",
      "        #print npages\n",
      "    else:\n",
      "        if start == 2: \n",
      "            start = 3\n",
      "            continue\n",
      "        # Print the repo urls\n",
      "        print s\n",
      "        \n",
      "#now need to go over the remaining pages        \n",
      "# from 2 to npages\n",
      "#np = unicode(npages)\n",
      "#print '/repo/all/'+ np + '?name=' + key"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": []
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Task 1A: Retrieve and store links from all pages"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Task 1B: Try several keywords, what keywords yield the largest number of repositories?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example 2. Search for 'site:bitbucket.org' via google."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import requests, json, sys, time, re, BeautifulSoup\n",
      "URL = 'https://www.google.com/search?q=site%3Abitbucket.org'\n",
      "r = requests .get(URL)\n",
      "t = r.text\n",
      "soup = BeautifulSoup.BeautifulSoup(t)\n",
      "start = 0\n",
      "npages = 1\n",
      "for link in soup.findAll('a'):\n",
      "    s = link.get('href')\n",
      "    m = re.search(r'url?q=https://bitbucket.org/([^&%]*)', s)\n",
      "    if m:\n",
      "        print m.group[1]    \n",
      "#now need to go over the remaining pages from google search\n",
      "# https://www.google.com/search?q=site%3Abitbucket.org&start=900\n",
      "# until "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": []
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Task 2A: Retrieve repository links over all pages returned by google search\n",
      " "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Merge all the lists obtained so far"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}